---
{
  "area": "general",
  "title": "Principal component analysis",
  "year": null,
  "categories": [
    "dimensionality-reduction"
  ],
  "components": [],
  "thumbnail": "principal-component-analysis.png",
  "introduced_by": null,
  "links": [
    {
      "resource": "Papers With Code",
      "icon": "paperswithcode",
      "url": "https://paperswithcode.com/method/pca"
    },
    {
      "resource": "Wikipedia",
      "icon": "wikipedia",
      "url": "https://en.wikipedia.org/wiki/Principal_component_analysis"
    }
  ],
  "also_known_as": [
    "PCA"
  ]
}
---

Principle Components Analysis (PCA) is an unsupervised method primary used for dimensionality reduction within machine learning. PCA is calculated via a singular value decomposition (SVD) of the design matrix, or alternatively, by calculating the covariance matrix of the data and performing eigenvalue decomposition on the covariance matrix. The results of PCA provide a low-dimensional picture of the structure of the data and the leading (uncorrelated) latent factors determining variation in the data.

Source: [Papers With Code](https://paperswithcode.com/method/pca)  
Image source: [Wikipedia](https://en.wikipedia.org/wiki/Principal_component_analysis#/media/File:GaussianScatterPCA.svg)

---
{
  "title": "Skip-Thought Vectors",
  "date": "2015-06-22",
  "authors": [
    "Ryan Kiros",
    "Y. Zhu",
    "R. Salakhutdinov",
    "R. Zemel",
    "R. Urtasun",
    "A. Torralba",
    "S. Fidler"
  ],
  "abstract": "We describe an approach for unsupervised learning of a generic, distributed sentence encoder. Using the continuity of text from books, we train an encoder-decoder model that tries to reconstruct the surrounding sentences of an encoded passage. Sentences that share semantic and syntactic properties are thus mapped to similar vector representations. We next introduce a simple vocabulary expansion method to encode words that were not seen as part of training, allowing us to expand our vocabulary to a million words. After training our model, we extract and evaluate our vectors with linear models on 8 tasks: semantic relatedness, paraphrase detection, image-sentence ranking, question-type classification and 4 benchmark sentiment and subjectivity datasets. The end result is an off-the-shelf encoder that can produce highly generic sentence representations that are robust and perform well in practice.",
  "links": [
    {
      "resource": "PDF",
      "icon": "pdf",
      "url": "https://arxiv.org/pdf/1506.06726.pdf"
    },
    {
      "resource": "arXiv.org",
      "icon": "arxiv",
      "url": "https://arxiv.org/abs/1506.06726"
    },
    {
      "resource": "Semantic Scholar",
      "icon": "semanticscholar",
      "url": "https://www.semanticscholar.org/paper/6e795c6e9916174ae12349f5dc3f516570c17ce8"
    }
  ],
  "supervision": [],
  "tasks": [],
  "methods": [],
  "thumbnail": "skip-thought-vectors-thumb.jpg",
  "card": "skip-thought-vectors-card.jpg",
  "s2_paper_id": "6e795c6e9916174ae12349f5dc3f516570c17ce8"
}
---


---
{
  "title": "Unsupervised Tokenization for Machine Translation",
  "date": "2009-08-06",
  "authors": [
    "Tagyoung Chung",
    "Daniel Gildea"
  ],
  "abstract": "Training a statistical machine translation starts with tokenizing a parallel corpus. Some languages such as Chinese do not incorporate spacing in their writing system, which creates a challenge for tokenization. Moreover, morphologically rich languages such as Korean present an even bigger challenge, since optimal token boundaries for machine translation in these languages are often unclear. Both rule-based solutions and statistical solutions are currently used. In this paper, we present unsupervised methods to solve tokenization problem. Our methods incorporate information available from parallel corpus to determine a good tokenization for machine translation.",
  "links": [
    {
      "title": "PDF",
      "type": "pdf",
      "url": "http://aclweb.org/anthology//D/D09/D09-1075.pdf"
    },
    {
      "title": "Semantic Scholar",
      "type": "semanticscholar",
      "url": "https://www.semanticscholar.org/paper/a575a9f508240a17ecf4e253984ab3ad5af5b8d1"
    }
  ],
  "supervision": [],
  "tasks": [],
  "methods": [],
  "thumbnail": "unsupervised-tokenization-for-machine-translation-thumb.jpg",
  "card": "unsupervised-tokenization-for-machine-translation-card.jpg",
  "s2_paper_id": "a575a9f508240a17ecf4e253984ab3ad5af5b8d1"
}
---


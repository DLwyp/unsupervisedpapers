---
{
  "title": "Split-Brain Autoencoders: Unsupervised Learning by Cross-Channel Prediction",
  "date": "2016-11-29",
  "authors": [
    "Richard Zhang",
    "Phillip Isola",
    "Alexei A. Efros"
  ],
  "abstract": "We propose split-brain autoencoders, a straightforward modification of the traditional autoencoder architecture, for unsupervised representation learning. The method adds a split to the network, resulting in two disjoint sub-networks. Each sub-network is trained to perform a difficult task &#x2013; predicting one subset of the data channels from another. Together, the sub-networks extract features from the entire input signal. By forcing the network to solve cross-channel prediction tasks, we induce a representation within the network which transfers well to other, unseen tasks. This method achieves state-of-the-art performance on several large-scale transfer learning benchmarks.",
  "links": [
    {
      "title": "PDF",
      "type": "pdf",
      "url": "https://arxiv.org/pdf/1611.09842.pdf"
    },
    {
      "title": "arXiv.org",
      "type": "arxiv",
      "url": "https://arxiv.org/abs/1611.09842"
    },
    {
      "title": "Semantic Scholar",
      "type": "semanticscholar",
      "url": "https://www.semanticscholar.org/paper/62f3d3015cee122bd147d7d878c85f70cc15680d"
    }
  ],
  "supervision": [],
  "tasks": [],
  "methods": [],
  "thumbnail": "split-brain-autoencoders-unsupervised-learning-by-cross-channel-prediction-thumb.jpg",
  "card": "split-brain-autoencoders-unsupervised-learning-by-cross-channel-prediction-card.jpg",
  "s2_paper_id": "62f3d3015cee122bd147d7d878c85f70cc15680d"
}
---


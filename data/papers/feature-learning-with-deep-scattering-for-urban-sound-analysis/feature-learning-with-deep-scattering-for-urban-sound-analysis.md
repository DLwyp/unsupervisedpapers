---
{
  "title": "Feature learning with deep scattering for urban sound analysis",
  "date": "2015-12-28",
  "authors": [
    "Justin Salamon",
    "J. Bello"
  ],
  "abstract": "In this paper we evaluate the scattering transform as an alternative signal representation to the mel-spectrogram in the context of unsupervised feature learning for urban sound classification. We show that we can obtain comparable (or better) performance using the scattering transform whilst reducing both the amount of training data required for feature learning and the size of the learned codebook by an order of magnitude. In both cases the improvement is attributed to the local phase invariance of the representation. We also observe improved classification of sources in the background of the auditory scene, a result that provides further support for the importance of temporal modulation in sound segregation.",
  "links": [
    {
      "title": "PDF",
      "type": "pdf",
      "url": "http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7362478"
    },
    {
      "title": "Semantic Scholar",
      "type": "semanticscholar",
      "url": "https://www.semanticscholar.org/paper/fdba38391a987ef12a6edd5455e676469c54e1dd"
    }
  ],
  "supervision": [],
  "tasks": [],
  "methods": [],
  "thumbnail": "feature-learning-with-deep-scattering-for-urban-sound-analysis-thumb.jpg",
  "card": "feature-learning-with-deep-scattering-for-urban-sound-analysis-card.jpg",
  "s2_paper_id": "fdba38391a987ef12a6edd5455e676469c54e1dd"
}
---


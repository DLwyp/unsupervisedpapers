---
{
  "title": "Feature Selection for Clustering",
  "date": "2000-04-18",
  "authors": [
    "M. Dash",
    "Huan Liu"
  ],
  "abstract": "Clustering is an important data mining task. Data mining often concerns large and high-dimensional data but unfortunately most of the clustering algorithms in the literature are sensitive to largeness or high-dimensionality or both. Different features affect clusters differently, some are important for clusters while others may hinder the clustering task. An efficient way of handling it is by selecting a subset of important features. It helps in finding clusters efficiently, understanding the data better and reducing data size for efficient storage, collection and processing. The task of finding original important features for unsupervised data is largely untouched. Traditional feature selection algorithms work only for supervised data where class information is available. For unsupervised data, without class information, often principal components (PCs) are used, but PCs still require all features and they may be difficult to understand. Our approach: first features are ranked according to their importance on clustering and then a subset of important features are selected. For large data we use a scalable method using sampling. Empirical evaluation shows the effectiveness and scalability of our approach for benchmark and synthetic data sets.",
  "links": [
    {
      "title": "PDF",
      "type": "pdf",
      "url": "https://doi.org/10.1007/3-540-45571-X_13"
    },
    {
      "title": "Semantic Scholar",
      "type": "semanticscholar",
      "url": "https://www.semanticscholar.org/paper/8c94656d51f49a65bd53e8ad1902c12920a7e5fb"
    }
  ],
  "supervision": [],
  "tasks": [],
  "methods": [],
  "thumbnail": "feature-selection-for-clustering-thumb.jpg",
  "card": "feature-selection-for-clustering-card.jpg",
  "s2_paper_id": "8c94656d51f49a65bd53e8ad1902c12920a7e5fb"
}
---


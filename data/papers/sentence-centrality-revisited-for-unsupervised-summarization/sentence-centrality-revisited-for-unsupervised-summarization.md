---
{
  "title": "Sentence Centrality Revisited for Unsupervised Summarization",
  "date": "2019-06-08",
  "authors": [
    "H. Zheng",
    "Mirella Lapata"
  ],
  "abstract": "Single document summarization has enjoyed renewed interests in recent years thanks to the popularity of neural network models and the availability of large-scale datasets. In this paper we develop an unsupervised approach arguing that it is unrealistic to expect large-scale and high-quality training data to be available or created for different types of summaries, domains, or languages. We revisit a popular graph-based ranking algorithm and modify how node (aka sentence) centrality is computed in two ways: (a)~we employ BERT, a state-of-the-art neural representation learning model to better capture sentential meaning and (b)~we build graphs with directed edges arguing that the contribution of any two nodes to their respective centrality is influenced by their relative position in a document. Experimental results on three news summarization datasets representative of different languages and writing styles show that our approach outperforms strong baselines by a wide margin.",
  "links": [
    {
      "title": "PDF",
      "type": "pdf",
      "url": "https://arxiv.org/pdf/1906.03508.pdf"
    },
    {
      "title": "arXiv.org",
      "type": "arxiv",
      "url": "https://arxiv.org/abs/1906.03508"
    },
    {
      "title": "Semantic Scholar",
      "type": "semanticscholar",
      "url": "https://www.semanticscholar.org/paper/5ccfbddcfd8684a97fe1b693b8b510526936f553"
    }
  ],
  "supervision": [],
  "tasks": [],
  "methods": [],
  "thumbnail": "sentence-centrality-revisited-for-unsupervised-summarization-thumb.jpg",
  "card": "sentence-centrality-revisited-for-unsupervised-summarization-card.jpg",
  "s2_paper_id": "5ccfbddcfd8684a97fe1b693b8b510526936f553"
}
---


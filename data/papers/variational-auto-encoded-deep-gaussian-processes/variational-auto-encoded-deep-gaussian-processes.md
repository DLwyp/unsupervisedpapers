---
{
  "title": "Variational Auto-encoded Deep Gaussian Processes",
  "date": "2015-11-19",
  "authors": [
    "Z. Dai",
    "A. Damianou",
    "J. Gonz√°lez",
    "N. Lawrence"
  ],
  "abstract": "We develop a scalable deep non-parametric generative model by augmenting deep Gaussian processes with a recognition model. Inference is performed in a novel scalable variational framework where the variational posterior distributions are reparametrized through a multilayer perceptron. The key aspect of this reformulation is that it prevents the proliferation of variational parameters which otherwise grow linearly in proportion to the sample size. We derive a new formulation of the variational lower bound that allows us to distribute most of the computation in a way that enables to handle datasets of the size of mainstream deep learning tasks. We show the efficacy of the method on a variety of challenges including deep unsupervised learning and deep Bayesian optimization.",
  "links": [
    {
      "resource": "PDF",
      "icon": "pdf",
      "url": "https://arxiv.org/pdf/1511.06455.pdf"
    },
    {
      "resource": "arXiv.org",
      "icon": "arxiv",
      "url": "https://arxiv.org/abs/1511.06455"
    },
    {
      "resource": "Semantic Scholar",
      "icon": "semanticscholar",
      "url": "https://www.semanticscholar.org/paper/d180046b07f94054b188a73c45033c7cf65d5e4c"
    }
  ],
  "supervision": [],
  "tasks": [],
  "methods": [],
  "thumbnail": "variational-auto-encoded-deep-gaussian-processes-thumb.jpg",
  "card": "variational-auto-encoded-deep-gaussian-processes-card.jpg",
  "s2_paper_id": "d180046b07f94054b188a73c45033c7cf65d5e4c"
}
---


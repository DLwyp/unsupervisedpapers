---
{
  "title": "Unsupervised Cross-Domain Transfer in Policy Gradient Reinforcement Learning via Manifold Alignment",
  "date": "2015-01-25",
  "authors": [
    "Haitham Bou-Ammar",
    "E. Eaton",
    "P. Ruvolo",
    "M. Taylor"
  ],
  "abstract": "The success of applying policy gradient reinforcement learning (RL) to difficult control tasks hinges crucially on the ability to determine a sensible initialization for the policy. Transfer learning methods tackle this problem by reusing knowledge gleaned from solving other related tasks. In the case of multiple task domains, these algorithms require an inter-task mapping to facilitate knowledge transfer across domains. However, there are currently no general methods to learn an inter-task mapping without requiring either background knowledge that is not typically present in RL settings, or an expensive analysis of an exponential number of inter-task mappings in the size of the state and action spaces. \n \nThis paper introduces an autonomous framework that uses unsupervised manifold alignment to learn intertask mappings and effectively transfer samples between different task domains. Empirical results on diverse dynamical systems, including an application to quadrotor control, demonstrate its effectiveness for cross-domain transfer in the context of policy gradient RL.",
  "links": [
    {
      "title": "PDF",
      "type": "pdf",
      "url": "https://pdfs.semanticscholar.org/92e5/5c7d51e584a7fb8ec134fe2ec2b88defb4cc.pdf"
    },
    {
      "title": "Semantic Scholar",
      "type": "semanticscholar",
      "url": "https://www.semanticscholar.org/paper/a3f90251c8107b8e79e9cc8fb17a4610c3dc2abd"
    }
  ],
  "supervision": [],
  "tasks": [],
  "methods": [],
  "thumbnail": "unsupervised-cross-domain-transfer-in-policy-gradient-reinforcement-learning-via-manifold-alignment-thumb.jpg",
  "card": "unsupervised-cross-domain-transfer-in-policy-gradient-reinforcement-learning-via-manifold-alignment-card.jpg",
  "s2_paper_id": "a3f90251c8107b8e79e9cc8fb17a4610c3dc2abd"
}
---


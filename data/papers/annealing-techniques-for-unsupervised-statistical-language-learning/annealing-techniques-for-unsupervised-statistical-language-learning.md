---
{
  "title": "Annealing Techniques For Unsupervised Statistical Language Learning",
  "date": "2004-07-21",
  "authors": [
    "Noah A. Smith",
    "J. Eisner"
  ],
  "abstract": "Exploiting unannotated natural language data is hard largely because unsupervised parameter estimation is hard. We describe deterministic annealing (Rose et al., 1990) as an appealing alternative to the Expectation-Maximization algorithm (Dempster et al., 1977). Seeking to avoid search error, DA begins by globally maximizing an easy concave function and maintains a local maximum as it gradually morphs the function into the desired non-concave likelihood function. Applying DA to parsing and tagging models is shown to be straightforward; significant improvements over EM are shown on a part-of-speech tagging task. We describe a variant, skewed DA, which can incorporate a good initializer when it is available, and show significant improvements over EM on a grammar induction task.",
  "links": [
    {
      "resource": "PDF",
      "icon": "pdf",
      "url": "https://pdfs.semanticscholar.org/ec16/886630e124876c9b3c666727c829c7e62378.pdf"
    },
    {
      "resource": "Semantic Scholar",
      "icon": "semanticscholar",
      "url": "https://www.semanticscholar.org/paper/ec16886630e124876c9b3c666727c829c7e62378"
    }
  ],
  "supervision": [],
  "tasks": [],
  "methods": [],
  "thumbnail": "annealing-techniques-for-unsupervised-statistical-language-learning-thumb.jpg",
  "card": "annealing-techniques-for-unsupervised-statistical-language-learning-card.jpg",
  "s2_paper_id": "ec16886630e124876c9b3c666727c829c7e62378"
}
---


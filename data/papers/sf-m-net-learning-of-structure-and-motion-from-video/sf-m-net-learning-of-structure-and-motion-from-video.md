---
{
  "title": "SfM-Net: Learning of Structure and Motion from Video",
  "date": "2017-04-25",
  "authors": [
    "Sudheendra Vijayanarasimhan",
    "S. Ricco",
    "C. Schmid",
    "R. Sukthankar",
    "K. Fragkiadaki"
  ],
  "abstract": "We propose SfM-Net, a geometry-aware neural network for motion estimation in videos that decomposes frame-to-frame pixel motion in terms of scene and object depth, camera motion and 3D object rotations and translations. Given a sequence of frames, SfM-Net predicts depth, segmentation, camera and rigid object motions, converts those into a dense frame-to-frame motion field (optical flow), differentiably warps frames in time to match pixels and back-propagates. The model can be trained with various degrees of supervision: 1) self-supervised by the re-projection photometric error (completely unsupervised), 2) supervised by ego-motion (camera motion), or 3) supervised by depth (e.g., as provided by RGBD sensors). SfM-Net extracts meaningful depth estimates and successfully estimates frame-to-frame camera rotations and translations. It often successfully segments the moving objects in the scene, even though such supervision is never provided.",
  "links": [
    {
      "title": "PDF",
      "type": "pdf",
      "url": "https://arxiv.org/pdf/1704.07804.pdf"
    },
    {
      "title": "arXiv.org",
      "type": "arxiv",
      "url": "https://arxiv.org/abs/1704.07804"
    },
    {
      "title": "Semantic Scholar",
      "type": "semanticscholar",
      "url": "https://www.semanticscholar.org/paper/ab6b8671d3baef80f87ad76a3e4ce452aa1b6467"
    }
  ],
  "supervision": [],
  "tasks": [],
  "methods": [],
  "thumbnail": "sf-m-net-learning-of-structure-and-motion-from-video-thumb.jpg",
  "card": "sf-m-net-learning-of-structure-and-motion-from-video-card.jpg",
  "s2_paper_id": "ab6b8671d3baef80f87ad76a3e4ce452aa1b6467"
}
---


---
{
  "title": "Unsupervised Learning of Long-Term Motion Dynamics for Videos",
  "date": "2017-01-07",
  "authors": [
    "Zelun Luo",
    "B. Peng",
    "De-An Huang",
    "Alexandre Alahi",
    "Li Fei-Fei"
  ],
  "abstract": "We present an unsupervised representation learning approach that compactly encodes the motion dependencies in videos. Given a pair of images from a video clip, our framework learns to predict the long-term 3D motions. To reduce the complexity of the learning framework, we propose to describe the motion as a sequence of atomic 3D flows computed with RGB-D modality. We use a Recurrent Neural Network based Encoder-Decoder framework to predict these sequences of flows. We argue that in order for the decoder to reconstruct these sequences, the encoder must learn a robust video representation that captures long-term motion dependencies and spatial-temporal relations. We demonstrate the effectiveness of our learned temporal representations on activity classification across multiple modalities and datasets such as NTU RGB+D and MSR Daily Activity 3D. Our framework is generic to any input modality, i.e., RGB, depth, and RGB-D videos.",
  "links": [
    {
      "title": "PDF",
      "type": "pdf",
      "url": "https://arxiv.org/pdf/1701.01821.pdf"
    },
    {
      "title": "arXiv.org",
      "type": "arxiv",
      "url": "https://arxiv.org/abs/1701.01821"
    },
    {
      "title": "Semantic Scholar",
      "type": "semanticscholar",
      "url": "https://www.semanticscholar.org/paper/cd5d8244038c4aba6d9b5c6a114b5e6c9c087b37"
    }
  ],
  "supervision": [],
  "tasks": [],
  "methods": [],
  "thumbnail": "unsupervised-learning-of-long-term-motion-dynamics-for-videos-thumb.jpg",
  "card": "unsupervised-learning-of-long-term-motion-dynamics-for-videos-card.jpg",
  "s2_paper_id": "cd5d8244038c4aba6d9b5c6a114b5e6c9c087b37"
}
---


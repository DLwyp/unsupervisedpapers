---
{
  "title": "Co-attention CNNs for Unsupervised Object Co-segmentation",
  "date": "2018-07-13",
  "authors": [
    "Kuang-Jui Hsu",
    "Yen-Yu Lin",
    "Yung-Yu Chuang"
  ],
  "abstract": "Object co-segmentation aims to segment the common objects in images. This paper presents a CNNbased method that is unsupervised and end-to-end trainable to better solve this task. Our method is unsupervised in the sense that it does not require any training data in the form of object masks but merely a set of images jointly covering objects of a specific class. Our method comprises two collaborative CNN modules, a feature extractor and a co-attention map generator. The former module extracts the features of the estimated objects and backgrounds, and is derived based on the proposed co-attention loss, which minimizes interimage object discrepancy while maximizing intraimage figure-ground separation. The latter module is learned to generate co-attention maps by which the estimated figure-ground segmentation can better fit the former module. Besides the co-attention loss, the mask loss is developed to retain the whole objects and remove noises. Experiments show that our method achieves superior results, even outperforming the state-of-the-art, supervised methods.",
  "links": [
    {
      "title": "PDF",
      "type": "pdf",
      "url": "https://doi.org/10.24963/ijcai.2018%2F104"
    },
    {
      "title": "Semantic Scholar",
      "type": "semanticscholar",
      "url": "https://www.semanticscholar.org/paper/b1a6cb4a4cfaba6532e277f0fd7cef150cba99ea"
    }
  ],
  "supervision": [],
  "tasks": [],
  "methods": [],
  "thumbnail": "co-attention-cnns-for-unsupervised-object-co-segmentation-thumb.jpg",
  "card": "co-attention-cnns-for-unsupervised-object-co-segmentation-card.jpg",
  "s2_paper_id": "b1a6cb4a4cfaba6532e277f0fd7cef150cba99ea"
}
---


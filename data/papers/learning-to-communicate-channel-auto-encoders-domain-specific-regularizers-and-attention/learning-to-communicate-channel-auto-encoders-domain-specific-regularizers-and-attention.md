---
{
  "title": "Learning to communicate: Channel auto-encoders, domain specific regularizers, and attention",
  "date": "2016-08-23",
  "authors": [
    "T. O'Shea",
    "Kiran Karra",
    "T. Clancy"
  ],
  "abstract": "We address the problem of learning an efficient and adaptive physical layer encoding to communicate binary information over an impaired channel. In contrast to traditional work, we treat the problem an unsupervised machine learning problem focusing on optimizing reconstruction loss through artificial impairment layers in an autoencoder (we term this a channel autoencoder) and introduce several new regularizing layers which emulate common wireless channel impairments. We also discuss the role of attention models in the form of the radio transformer network for helping to recover canonical signal representations before decoding. We demonstrate some promising initial capacity results from this approach and address remaining challenges before such a system could become practical.",
  "links": [
    {
      "resource": "PDF",
      "icon": "pdf",
      "url": "https://arxiv.org/pdf/1608.06409.pdf"
    },
    {
      "resource": "arXiv.org",
      "icon": "arxiv",
      "url": "https://arxiv.org/abs/1608.06409"
    },
    {
      "resource": "Semantic Scholar",
      "icon": "semanticscholar",
      "url": "https://www.semanticscholar.org/paper/84590524abadda4761829b4d5f19d3eddee55645"
    }
  ],
  "supervision": [],
  "tasks": [],
  "methods": [],
  "thumbnail": "learning-to-communicate-channel-auto-encoders-domain-specific-regularizers-and-attention-thumb.jpg",
  "card": "learning-to-communicate-channel-auto-encoders-domain-specific-regularizers-and-attention-card.jpg",
  "s2_paper_id": "84590524abadda4761829b4d5f19d3eddee55645"
}
---


---
{
  "title": "MONet: Unsupervised Scene Decomposition and Representation",
  "date": "2019-01-22",
  "authors": [
    "C. Burgess",
    "Lo√Øc Matthey",
    "Nicholas Watters",
    "Rishabh Kabra",
    "I. Higgins",
    "M. Botvinick",
    "Alexander Lerchner"
  ],
  "abstract": "The ability to decompose scenes in terms of abstract building blocks is crucial for general intelligence. Where those basic building blocks share meaningful properties, interactions and other regularities across scenes, such decompositions can simplify reasoning and facilitate imagination of novel scenarios. In particular, representing perceptual observations in terms of entities should improve data efficiency and transfer performance on a wide range of tasks. Thus we need models capable of discovering useful decompositions of scenes by identifying units with such regularities and representing them in a common format. To address this problem, we have developed the Multi-Object Network (MONet). In this model, a VAE is trained end-to-end together with a recurrent attention network -- in a purely unsupervised manner -- to provide attention masks around, and reconstructions of, regions of images. We show that this model is capable of learning to decompose and represent challenging 3D scenes into semantically meaningful components, such as objects and background elements.",
  "links": [
    {
      "resource": "PDF",
      "icon": "pdf",
      "url": "https://arxiv.org/pdf/1901.11390.pdf"
    },
    {
      "resource": "arXiv.org",
      "icon": "arxiv",
      "url": "https://arxiv.org/abs/1901.11390"
    },
    {
      "resource": "Semantic Scholar",
      "icon": "semanticscholar",
      "url": "https://www.semanticscholar.org/paper/d25b1edda507cba944938ec8784d8b124c2381a5"
    }
  ],
  "supervision": [],
  "tasks": [],
  "methods": [],
  "thumbnail": "monet-unsupervised-scene-decomposition-and-representation-thumb.jpg",
  "card": "monet-unsupervised-scene-decomposition-and-representation-card.jpg",
  "s2_paper_id": "d25b1edda507cba944938ec8784d8b124c2381a5"
}
---


---
{
  "title": "Differentiable pooling for unsupervised speaker adaptation",
  "date": "2015-04-19",
  "authors": [
    "P. Swietojanski",
    "S. Renals"
  ],
  "abstract": "This paper proposes a differentiable pooling mechanism to perform model-based neural network speaker adaptation. The proposed technique learns a speaker-dependent combination of activations within pools of hidden units, was shown to work well unsupervised, and does not require speaker-adaptive training. We have conducted a set of experiments on the TED talks data, as used in the IWSLT evaluations. Our results indicate that the approach can reduce word error rates (WERs) on standard IWSLT test sets by about 5-11% relative compared to speaker-independent systems and was found complementary to the recently proposed learning hidden units contribution (LHUC) approach, reducing WER by 6-13% relative. Both methods were also found to work well when adapting with small amounts of unsupervised data - 10 seconds is able to decrease the WER by 5% relative compared to the baseline speaker independent system.",
  "links": [
    {
      "resource": "PDF",
      "icon": "pdf",
      "url": "http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7178783"
    },
    {
      "resource": "Semantic Scholar",
      "icon": "semanticscholar",
      "url": "https://www.semanticscholar.org/paper/4bf7ba0ccc0cdfee2ce24fa3dcdd8bcdfdc9d291"
    }
  ],
  "supervision": [],
  "tasks": [],
  "methods": [],
  "thumbnail": "differentiable-pooling-for-unsupervised-speaker-adaptation-thumb.jpg",
  "card": "differentiable-pooling-for-unsupervised-speaker-adaptation-card.jpg",
  "s2_paper_id": "4bf7ba0ccc0cdfee2ce24fa3dcdd8bcdfdc9d291"
}
---


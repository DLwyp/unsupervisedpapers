---
{
  "title": "Unsupervised feature selection with ensemble learning",
  "authors": [
    "H. Elghazel",
    "A. Aussem"
  ],
  "abstract": "In this paper, we show that the way internal estimates are used to measure variable importance in Random Forests are also applicable to feature selection in unsupervised learning. We propose a new method called Random Cluster Ensemble (RCE for short), that estimates the out-of-bag feature importance from an ensemble of partitions. Each partition is constructed using a different bootstrap sample and a random subset of the features. We provide empirical results on nineteen benchmark data sets indicating that RCE, boosted with a recursive feature elimination scheme (RFE) (Guyon and Elisseeff, Journal of Machine Learning Research, 3:1157â€“1182, 2003), can lead to significant improvement in terms of clustering accuracy, over several state-of-the-art supervised and unsupervised algorithms, with a very limited subset of features. The method shows promise to deal with very large domains. All results, datasets and algorithms are available on line (http://perso.univ-lyon1.fr/haytham.elghazel/RCE.zip).",
  "links": [
    {
      "title": "PDF",
      "type": "pdf",
      "url": "https://doi.org/10.1007/s10994-013-5337-8"
    },
    {
      "title": "Semantic Scholar",
      "type": "semanticscholar",
      "url": "https://www.semanticscholar.org/paper/320bf015430084f0191e367572499179e4f18d91"
    }
  ],
  "supervision": [],
  "tasks": [],
  "methods": [],
  "thumbnail": "unsupervised-feature-selection-with-ensemble-learning-thumb.jpg",
  "card": "unsupervised-feature-selection-with-ensemble-learning-card.jpg",
  "s2_paper_id": "320bf015430084f0191e367572499179e4f18d91"
}
---


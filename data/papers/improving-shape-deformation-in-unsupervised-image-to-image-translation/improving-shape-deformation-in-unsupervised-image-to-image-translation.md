---
{
  "title": "Improving Shape Deformation in Unsupervised Image-to-Image Translation",
  "date": "2018-08-13",
  "authors": [
    "Aaron Gokaslan",
    "V. Ramanujan",
    "D. Ritchie",
    "K. Kim",
    "J. Tompkin"
  ],
  "abstract": "Unsupervised image-to-image translation techniques are able to map local texture between two domains, but they are typically unsuccessful when the domains require larger shape change. Inspired by semantic segmentation, we introduce a discriminator with dilated convolutions that is able to use information from across the entire image to train a more context-aware generator. This is coupled with a multi-scale perceptual loss that is better able to represent error in the underlying shape of objects. We demonstrate that this design is more capable of representing shape deformation in a challenging toy dataset, plus in complex mappings with significant dataset variation between humans, dolls, and anime faces, and between cats and dogs.",
  "links": [
    {
      "resource": "PDF",
      "icon": "pdf",
      "url": "https://arxiv.org/pdf/1808.04325.pdf"
    },
    {
      "resource": "arXiv.org",
      "icon": "arxiv",
      "url": "https://arxiv.org/abs/1808.04325"
    },
    {
      "resource": "Semantic Scholar",
      "icon": "semanticscholar",
      "url": "https://www.semanticscholar.org/paper/798cc4f05ac0699215d0083130c2793be17803fc"
    }
  ],
  "supervision": [],
  "tasks": [],
  "methods": [],
  "thumbnail": "improving-shape-deformation-in-unsupervised-image-to-image-translation-thumb.jpg",
  "card": "improving-shape-deformation-in-unsupervised-image-to-image-translation-card.jpg",
  "s2_paper_id": "798cc4f05ac0699215d0083130c2793be17803fc"
}
---


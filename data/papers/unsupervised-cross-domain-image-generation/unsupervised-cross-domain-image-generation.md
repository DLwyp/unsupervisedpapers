---
{
  "title": "Unsupervised Cross-Domain Image Generation",
  "date": "2016-11-07",
  "authors": [
    "Yaniv Taigman",
    "A. Polyak",
    "L. Wolf"
  ],
  "abstract": "We study the problem of transferring a sample in one domain to an analog sample in another domain. Given two related domains, S and T, we would like to learn a generative function G that maps an input sample from S to the domain T, such that the output of a given function f, which accepts inputs in either domains, would remain unchanged. Other than the function f, the training data is unsupervised and consist of a set of samples from each domain. The Domain Transfer Network (DTN) we present employs a compound loss function that includes a multiclass GAN loss, an f-constancy component, and a regularizing component that encourages G to map samples from T to themselves. We apply our method to visual domains including digits and face images and demonstrate its ability to generate convincing novel images of previously unseen entities, while preserving their identity.",
  "links": [
    {
      "resource": "PDF",
      "icon": "pdf",
      "url": "https://arxiv.org/pdf/1611.02200.pdf"
    },
    {
      "resource": "arXiv.org",
      "icon": "arxiv",
      "url": "https://arxiv.org/abs/1611.02200"
    },
    {
      "resource": "Semantic Scholar",
      "icon": "semanticscholar",
      "url": "https://www.semanticscholar.org/paper/04bd2907111855b9fde9413bb25b9788a4c03f26"
    }
  ],
  "supervision": [],
  "tasks": [],
  "methods": [],
  "thumbnail": "unsupervised-cross-domain-image-generation-thumb.jpg",
  "card": "unsupervised-cross-domain-image-generation-card.jpg",
  "s2_paper_id": "04bd2907111855b9fde9413bb25b9788a4c03f26"
}
---


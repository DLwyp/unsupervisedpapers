---
{
  "title": "Unsupervised cross-lingual knowledge transfer in DNN-based LVCSR",
  "date": "2012-12-01",
  "authors": [
    "P. Swietojanski",
    "A. Ghoshal",
    "S. Renals"
  ],
  "abstract": "We investigate the use of cross-lingual acoustic data to initialise deep neural network (DNN) acoustic models by means of unsupervised restricted Boltzmann machine (RBM) pre-training. DNNs for German are pretrained using one or all of German, Portuguese, Spanish and Swedish. The DNNs are used in a tandem configuration, where the network outputs are used as features for a hidden Markov model (HMM) whose emission densities are modeled by Gaussian mixture models (GMMs), as well as in a hybrid configuration, where the network outputs are used as the HMM state likelihoods. The experiments show that unsupervised pretraining is more crucial for the hybrid setups, particularly with limited amounts of transcribed training data. More importantly, unsupervised pretraining is shown to be language-independent.",
  "links": [
    {
      "title": "PDF",
      "type": "pdf",
      "url": "http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6424230"
    },
    {
      "title": "Semantic Scholar",
      "type": "semanticscholar",
      "url": "https://www.semanticscholar.org/paper/6f819d404c96697c3f43a16a6c8669f4edbfbf07"
    }
  ],
  "supervision": [],
  "tasks": [],
  "methods": [],
  "thumbnail": "unsupervised-cross-lingual-knowledge-transfer-in-dnn-based-lvcsr-thumb.jpg",
  "card": "unsupervised-cross-lingual-knowledge-transfer-in-dnn-based-lvcsr-card.jpg",
  "s2_paper_id": "6f819d404c96697c3f43a16a6c8669f4edbfbf07"
}
---


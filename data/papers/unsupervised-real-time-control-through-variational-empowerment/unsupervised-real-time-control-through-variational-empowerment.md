---
{
  "title": "Unsupervised Real-Time Control through Variational Empowerment",
  "date": "2017-10-13",
  "authors": [
    "M. Karl",
    "Maximilian SÃ¶lch",
    "Philip Becker-Ehmck",
    "Djalel Benbouzid",
    "P. V. D. Smagt",
    "J. Bayer"
  ],
  "abstract": "We introduce a methodology for efficiently computing a lower bound to empowerment, allowing it to be used as an unsupervised cost function for policy learning in real-time control. Empowerment, being the channel capacity between actions and states, maximises the influence of an agent on its near future. It has been shown to be a good model of biological behaviour in the absence of an extrinsic goal. But empowerment is also prohibitively hard to compute, especially in nonlinear continuous spaces. We introduce an efficient, amortised method for learning empowerment-maximising policies. We demonstrate that our algorithm can reliably handle continuous dynamical systems using system dynamics learned from raw data. The resulting policies consistently drive the agents into states where they can use their full potential.",
  "links": [
    {
      "resource": "PDF",
      "icon": "pdf",
      "url": "https://arxiv.org/pdf/1710.05101.pdf"
    },
    {
      "resource": "arXiv.org",
      "icon": "arxiv",
      "url": "https://arxiv.org/abs/1710.05101"
    },
    {
      "resource": "Semantic Scholar",
      "icon": "semanticscholar",
      "url": "https://www.semanticscholar.org/paper/725209bf1feaed869c3ba40450e0657ed6e335bc"
    }
  ],
  "supervision": [],
  "tasks": [],
  "methods": [],
  "thumbnail": "unsupervised-real-time-control-through-variational-empowerment-thumb.jpg",
  "card": "unsupervised-real-time-control-through-variational-empowerment-card.jpg",
  "s2_paper_id": "725209bf1feaed869c3ba40450e0657ed6e335bc"
}
---


---
{
  "title": "Generative Image Modeling Using Style and Structure Adversarial Networks",
  "date": "2016-03-17",
  "authors": [
    "X. Wang",
    "A. Gupta"
  ],
  "abstract": "Current generative frameworks use end-to-end learning and generate images by sampling from uniform noise distribution. However, these approaches ignore the most basic principle of image formation: images are product of: (a) Structure: the underlying 3D model; (b) Style: the texture mapped onto structure. In this paper, we factorize the image generation process and propose Style and Structure Generative Adversarial Network (\\({\\text {S}^2}\\)-GAN). Our \\({\\text {S}^2}\\)-GAN has two components: the Structure-GAN generates a surface normal map; the Style-GAN takes the surface normal map as input and generates the 2D image. Apart from a real vs. generated loss function, we use an additional loss with computed surface normals from generated images. The two GANs are first trained independently, and then merged together via joint learning. We show our \\({\\text {S}^2}\\)-GAN model is interpretable, generates more realistic images and can be used to learn unsupervised RGBD representations.",
  "links": [
    {
      "title": "PDF",
      "type": "pdf",
      "url": "https://arxiv.org/pdf/1603.05631.pdf"
    },
    {
      "title": "arXiv.org",
      "type": "arxiv",
      "url": "https://arxiv.org/abs/1603.05631"
    },
    {
      "title": "Semantic Scholar",
      "type": "semanticscholar",
      "url": "https://www.semanticscholar.org/paper/9c763df6843aba88d7fb3ab3c55a5937a5f39276"
    }
  ],
  "supervision": [],
  "tasks": [],
  "methods": [],
  "thumbnail": "generative-image-modeling-using-style-and-structure-adversarial-networks-thumb.jpg",
  "card": "generative-image-modeling-using-style-and-structure-adversarial-networks-card.jpg",
  "s2_paper_id": "9c763df6843aba88d7fb3ab3c55a5937a5f39276"
}
---


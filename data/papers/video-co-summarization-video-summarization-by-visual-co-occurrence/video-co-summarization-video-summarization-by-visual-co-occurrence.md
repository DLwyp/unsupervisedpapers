---
{
  "title": "Video co-summarization: Video summarization by visual co-occurrence",
  "date": "2015-06-07",
  "authors": [
    "Wen-Sheng Chu",
    "Yale Song",
    "A. Jaimes"
  ],
  "abstract": "We present video co-summarization, a novel perspective to video summarization that exploits visual co-occurrence across multiple videos. Motivated by the observation that important visual concepts tend to appear repeatedly across videos of the same topic, we propose to summarize a video by finding shots that co-occur most frequently across videos collected using a topic keyword. The main technical challenge is dealing with the sparsity of co-occurring patterns, out of hundreds to possibly thousands of irrelevant shots in videos being considered. To deal with this challenge, we developed a Maximal Biclique Finding (MBF) algorithm that is optimized to find sparsely co-occurring patterns, discarding less co-occurring patterns even if they are dominant in one video. Our algorithm is parallelizable with closed-form updates, thus can easily scale up to handle a large number of videos simultaneously. We demonstrate the effectiveness of our approach on motion capture and self-compiled YouTube datasets. Our results suggest that summaries generated by visual co-occurrence tend to match more closely with human generated summaries, when compared to several popular unsupervised techniques.",
  "links": [
    {
      "resource": "PDF",
      "icon": "pdf",
      "url": "http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7298981"
    },
    {
      "resource": "Semantic Scholar",
      "icon": "semanticscholar",
      "url": "https://www.semanticscholar.org/paper/12ac574da38a7ee39307c1eee44eefed727d5eda"
    }
  ],
  "supervision": [],
  "tasks": [],
  "methods": [],
  "thumbnail": "video-co-summarization-video-summarization-by-visual-co-occurrence-thumb.jpg",
  "card": "video-co-summarization-video-summarization-by-visual-co-occurrence-card.jpg",
  "s2_paper_id": "12ac574da38a7ee39307c1eee44eefed727d5eda"
}
---


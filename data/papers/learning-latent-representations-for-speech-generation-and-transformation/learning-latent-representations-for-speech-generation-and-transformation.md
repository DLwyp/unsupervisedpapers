---
{
  "title": "Learning Latent Representations for Speech Generation and Transformation",
  "date": "2017-04-13",
  "authors": [
    "Wei-Ning Hsu",
    "Yu Zhang",
    "James R. Glass"
  ],
  "abstract": "An ability to model a generative process and learn a latent representation for speech in an unsupervised fashion will be crucial to process vast quantities of unlabelled speech data. Recently, deep probabilistic generative models such as Variational Autoencoders (VAEs) have achieved tremendous success in modeling natural images. In this paper, we apply a convolutional VAE to model the generative process of natural speech. We derive latent space arithmetic operations to disentangle learned latent representations. We demonstrate the capability of our model to modify the phonetic content or the speaker identity for speech segments using the derived operations, without the need for parallel supervisory data.",
  "links": [
    {
      "title": "PDF",
      "type": "pdf",
      "url": "https://arxiv.org/pdf/1704.04222.pdf"
    },
    {
      "title": "arXiv.org",
      "type": "arxiv",
      "url": "https://arxiv.org/abs/1704.04222"
    },
    {
      "title": "Semantic Scholar",
      "type": "semanticscholar",
      "url": "https://www.semanticscholar.org/paper/4c20dff792bc447fab730e05f5e997694b67a11e"
    }
  ],
  "supervision": [],
  "tasks": [],
  "methods": [],
  "thumbnail": "learning-latent-representations-for-speech-generation-and-transformation-thumb.jpg",
  "card": "learning-latent-representations-for-speech-generation-and-transformation-card.jpg",
  "s2_paper_id": "4c20dff792bc447fab730e05f5e997694b67a11e"
}
---


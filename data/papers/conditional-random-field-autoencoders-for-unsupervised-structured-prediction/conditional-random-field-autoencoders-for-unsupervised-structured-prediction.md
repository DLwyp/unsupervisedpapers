---
{
  "title": "Conditional Random Field Autoencoders for Unsupervised Structured Prediction",
  "date": "2014-11-04",
  "authors": [
    "Waleed Ammar",
    "Chris Dyer",
    "Noah A. Smith"
  ],
  "abstract": "We introduce a framework for unsupervised learning of structured predictors with overlapping, global features. Each input's latent representation is predicted conditional on the observed data using a feature-rich conditional random field (CRF). Then a reconstruction of the input is (re)generated, conditional on the latent structure, using a generative model which factorizes similarly to the CRF. The autoencoder formulation enables efficient exact inference without resorting to unrealistic independence assumptions or restricting the kinds of features that can be used. We illustrate connections to traditional autoencoders, posterior regularization, and multi-view learning. We then show competitive results with instantiations of the framework for two canonical tasks in natural language processing: part-of-speech induction and bitext word alignment, and show that training the proposed model can be substantially more efficient than a comparable feature-rich baseline.",
  "links": [
    {
      "title": "PDF",
      "type": "pdf",
      "url": "https://arxiv.org/pdf/1411.1147.pdf"
    },
    {
      "title": "arXiv.org",
      "type": "arxiv",
      "url": "https://arxiv.org/abs/1411.1147"
    },
    {
      "title": "Semantic Scholar",
      "type": "semanticscholar",
      "url": "https://www.semanticscholar.org/paper/417711c3093c0cfacb86a4ea9c8d5bcdae7d39e0"
    }
  ],
  "supervision": [],
  "tasks": [],
  "methods": [],
  "thumbnail": "conditional-random-field-autoencoders-for-unsupervised-structured-prediction-thumb.jpg",
  "card": "conditional-random-field-autoencoders-for-unsupervised-structured-prediction-card.jpg",
  "s2_paper_id": "417711c3093c0cfacb86a4ea9c8d5bcdae7d39e0"
}
---


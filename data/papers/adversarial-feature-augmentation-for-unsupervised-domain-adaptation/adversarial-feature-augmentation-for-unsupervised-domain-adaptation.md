---
{
  "title": "Adversarial Feature Augmentation for Unsupervised Domain Adaptation",
  "date": "2017-11-23",
  "authors": [
    "Riccardo Volpi",
    "Pietro Morerio",
    "S. Savarese",
    "Vittorio Murino"
  ],
  "abstract": "Recent works showed that Generative Adversarial Networks (GANs) can be successfully applied in unsupervised domain adaptation, where, given a labeled source dataset and an unlabeled target dataset, the goal is to train powerful classifiers for the target samples. In particular, it was shown that a GAN objective function can be used to learn target features indistinguishable from the source ones. In this work, we extend this framework by (i) forcing the learned feature extractor to be domain-invariant, and (ii) training it through data augmentation in the feature space, namely performing feature augmentation. While data augmentation in the image space is a well established technique in deep learning, feature augmentation has not yet received the same level of attention. We accomplish it by means of a feature generator trained by playing the GAN minimax game against source features. Results show that both enforcing domain-invariance and performing feature augmentation lead to superior or comparable performance to state-of-the-art results in several unsupervised domain adaptation benchmarks.",
  "links": [
    {
      "title": "PDF",
      "type": "pdf",
      "url": "https://arxiv.org/pdf/1711.08561.pdf"
    },
    {
      "title": "arXiv.org",
      "type": "arxiv",
      "url": "https://arxiv.org/abs/1711.08561"
    },
    {
      "title": "Semantic Scholar",
      "type": "semanticscholar",
      "url": "https://www.semanticscholar.org/paper/42563d601d30bb74a15855ef912692e45c72340e"
    }
  ],
  "supervision": [],
  "tasks": [],
  "methods": [],
  "thumbnail": "adversarial-feature-augmentation-for-unsupervised-domain-adaptation-thumb.jpg",
  "card": "adversarial-feature-augmentation-for-unsupervised-domain-adaptation-card.jpg",
  "s2_paper_id": "42563d601d30bb74a15855ef912692e45c72340e"
}
---


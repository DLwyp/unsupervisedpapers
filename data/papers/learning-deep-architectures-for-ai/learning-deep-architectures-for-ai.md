---
{
  "title": "Learning Deep Architectures for AI",
  "authors": [
    "Y. Bengio"
  ],
  "abstract": "Theoretical results strongly suggest that in order to learn the kind of complicated functions that can represent high-level abstractions (e.g. in vision, language, and other AI-level tasks), one needs deep architectures. Deep architectures are composed of multiple levels of non-linear operations, such as in neural nets with many hidden layers or in complicated propositional formulae re-using many sub-formulae. Searching the parameter space of deep architectures is a difficult optimization task, but learning algorithms such as those for Deep Belief Networks have recently been proposed to tackle this problem with notable success, beating the state-of-the-art in certain areas. This paper discusses the motivations and principles regarding learning algorithms for deep architectures, in particular those exploiting as building blocks unsupervised learning of single-layer models such as Restricted Boltzmann Machines, used to construct deeper models such as Deep Belief Networks.",
  "links": [
    {
      "title": "PDF",
      "type": "pdf",
      "url": "https://doi.org/10.1561/2200000006"
    },
    {
      "title": "Semantic Scholar",
      "type": "semanticscholar",
      "url": "https://www.semanticscholar.org/paper/e60ff004dde5c13ec53087872cfcdd12e85beb57"
    }
  ],
  "supervision": [],
  "tasks": [],
  "methods": [],
  "thumbnail": "learning-deep-architectures-for-ai-thumb.jpg",
  "card": "learning-deep-architectures-for-ai-card.jpg",
  "s2_paper_id": "e60ff004dde5c13ec53087872cfcdd12e85beb57"
}
---


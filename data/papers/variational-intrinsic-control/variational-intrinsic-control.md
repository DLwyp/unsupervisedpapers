---
{
  "title": "Variational Intrinsic Control",
  "date": "2016-11-22",
  "authors": [
    "K. Gregor",
    "Danilo Jimenez Rezende",
    "Daan Wierstra"
  ],
  "abstract": "In this paper we introduce a new unsupervised reinforcement learning method for discovering the set of intrinsic options available to an agent. This set is learned by maximizing the number of different states an agent can reliably reach, as measured by the mutual information between the set of options and option termination states. To this end, we instantiate two policy gradient based algorithms, one that creates an explicit embedding space of options and one that represents options implicitly. The algorithms also provide an explicit measure of empowerment in a given state that can be used by an empowerment maximizing agent. The algorithm scales well with function approximation and we demonstrate the applicability of the algorithm on a range of tasks.",
  "links": [
    {
      "resource": "PDF",
      "icon": "pdf",
      "url": "https://arxiv.org/pdf/1611.07507.pdf"
    },
    {
      "resource": "arXiv.org",
      "icon": "arxiv",
      "url": "https://arxiv.org/abs/1611.07507"
    },
    {
      "resource": "Semantic Scholar",
      "icon": "semanticscholar",
      "url": "https://www.semanticscholar.org/paper/afb42208cc499ede10a65af0dbe598e08556370d"
    }
  ],
  "supervision": [],
  "tasks": [],
  "methods": [],
  "thumbnail": "variational-intrinsic-control-thumb.jpg",
  "card": "variational-intrinsic-control-card.jpg",
  "s2_paper_id": "afb42208cc499ede10a65af0dbe598e08556370d"
}
---


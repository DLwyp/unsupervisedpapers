---
{
  "title": "XGAN: Unsupervised Image-to-Image Translation for many-to-many Mappings",
  "date": "2017-11-14",
  "authors": [
    "A. Royer",
    "Konstantinos Bousmalis",
    "S. Gouws",
    "Fred Bertsch",
    "Inbar Mosseri",
    "F. Cole",
    "Kevin Murphy"
  ],
  "abstract": "Style transfer usually refers to the task of applying color and texture information from a specific style image to a given content image while preserving the structure of the latter. Here we tackle the more generic problem of semantic style transfer: given two unpaired collections of images, we aim to learn a mapping between the corpus-level style of each collection, while preserving semantic content shared across the two domains. We introduce XGAN (\"Cross-GAN\"), a dual adversarial autoencoder, which captures a shared representation of the common domain semantic content in an unsupervised way, while jointly learning the domain-to-domain image translations in both directions. We exploit ideas from the domain adaptation literature and define a semantic consistency loss which encourages the model to preserve semantics in the learned embedding space. We report promising qualitative results for the task of face-to-cartoon translation. The cartoon dataset, CartoonSet, we collected for this purpose is publicly available at this http URL as a new benchmark for semantic style transfer.",
  "links": [
    {
      "title": "PDF",
      "type": "pdf",
      "url": "https://arxiv.org/pdf/1711.05139.pdf"
    },
    {
      "title": "arXiv.org",
      "type": "arxiv",
      "url": "https://arxiv.org/abs/1711.05139"
    },
    {
      "title": "Semantic Scholar",
      "type": "semanticscholar",
      "url": "https://www.semanticscholar.org/paper/a8ff837f67f9fe9e6f562f5de56784b93b4f9dfe"
    }
  ],
  "supervision": [],
  "tasks": [],
  "methods": [],
  "thumbnail": "xgan-unsupervised-image-to-image-translation-for-many-to-many-mappings-thumb.jpg",
  "card": "xgan-unsupervised-image-to-image-translation-for-many-to-many-mappings-card.jpg",
  "s2_paper_id": "a8ff837f67f9fe9e6f562f5de56784b93b4f9dfe"
}
---


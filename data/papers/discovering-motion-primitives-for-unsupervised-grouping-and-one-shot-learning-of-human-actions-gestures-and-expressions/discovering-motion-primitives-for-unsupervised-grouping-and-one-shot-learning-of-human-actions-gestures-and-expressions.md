---
{
  "title": "Discovering Motion Primitives for Unsupervised Grouping and One-Shot Learning of Human Actions, Gestures, and Expressions",
  "date": "2013-07-01",
  "authors": [
    "Y. Yang",
    "Imran Saleemi",
    "M. Shah"
  ],
  "abstract": "This paper proposes a novel representation of articulated human actions and gestures and facial expressions. The main goals of the proposed approach are: 1) to enable recognition using very few examples, i.e., one or k-shot learning, and 2) meaningful organization of unlabeled datasets by unsupervised clustering. Our proposed representation is obtained by automatically discovering high-level subactions or motion primitives, by hierarchical clustering of observed optical flow in four-dimensional, spatial, and motion flow space. The completely unsupervised proposed method, in contrast to state-of-the-art representations like bag of video words, provides a meaningful representation conducive to visual interpretation and textual labeling. Each primitive action depicts an atomic subaction, like directional motion of limb or torso, and is represented by a mixture of four-dimensional Gaussian distributions. For one--shot and k-shot learning, the sequence of primitive labels discovered in a test video are labeled using KL divergence, and can then be represented as a string and matched against similar strings of training videos. The same sequence can also be collapsed into a histogram of primitives or be used to learn a Hidden Markov model to represent classes. We have performed extensive experiments on recognition by one and k-shot learning as well as unsupervised action clustering on six human actions and gesture datasets, a composite dataset, and a database of facial expressions. These experiments confirm the validity and discriminative nature of the proposed representation.",
  "links": [
    {
      "resource": "PDF",
      "icon": "pdf",
      "url": "http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6365192"
    },
    {
      "resource": "Semantic Scholar",
      "icon": "semanticscholar",
      "url": "https://www.semanticscholar.org/paper/e5435b147d16bf1d537b33af21378186a8f7ada0"
    }
  ],
  "supervision": [],
  "tasks": [],
  "methods": [],
  "thumbnail": "discovering-motion-primitives-for-unsupervised-grouping-and-one-shot-learning-of-human-actions-gestures-and-expressions-thumb.jpg",
  "card": "discovering-motion-primitives-for-unsupervised-grouping-and-one-shot-learning-of-human-actions-gestures-and-expressions-card.jpg",
  "s2_paper_id": "e5435b147d16bf1d537b33af21378186a8f7ada0"
}
---


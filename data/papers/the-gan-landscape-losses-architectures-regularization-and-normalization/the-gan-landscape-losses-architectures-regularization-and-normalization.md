---
{
  "title": "The GAN Landscape: Losses, Architectures, Regularization, and Normalization",
  "date": "2018-06-05",
  "authors": [
    "Karol Kurach",
    "M. Lucic",
    "Xiaohua Zhai",
    "M. Michalski",
    "S. Gelly"
  ],
  "abstract": "Generative adversarial networks (GANs) are a class of deep generative models which aim to learn a target distribution in an unsupervised fashion. While they were successfully applied to many problems, training a GAN is a notoriously challenging task and requires a significant amount of hyperparameter tuning, neural architecture engineering, and a non-trivial amount of \"tricks\". The success in many practical applications coupled with the lack of a measure to quantify the failure modes of GANs resulted in a plethora of proposed losses, regularization and normalization schemes, and neural architectures. In this work we take a sober view of the current state of GANs from a practical perspective. We reproduce the current state of the art and go beyond fairly exploring the GAN landscape. We discuss common pitfalls and reproducibility issues, open-source our code on Github, and provide pre-trained models on TensorFlow Hub.",
  "links": [
    {
      "title": "PDF",
      "type": "pdf",
      "url": "https://arxiv.org/pdf/1807.04720.pdf"
    },
    {
      "title": "arXiv.org",
      "type": "arxiv",
      "url": "https://arxiv.org/abs/1807.04720"
    },
    {
      "title": "Semantic Scholar",
      "type": "semanticscholar",
      "url": "https://www.semanticscholar.org/paper/5b713f00eb7ebe21064321e73be8f32455a76799"
    }
  ],
  "supervision": [],
  "tasks": [],
  "methods": [],
  "thumbnail": "the-gan-landscape-losses-architectures-regularization-and-normalization-thumb.jpg",
  "card": "the-gan-landscape-losses-architectures-regularization-and-normalization-card.jpg",
  "s2_paper_id": "5b713f00eb7ebe21064321e73be8f32455a76799"
}
---


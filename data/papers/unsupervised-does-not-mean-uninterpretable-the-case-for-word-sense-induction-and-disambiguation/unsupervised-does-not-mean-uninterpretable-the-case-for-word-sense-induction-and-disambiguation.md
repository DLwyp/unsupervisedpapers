---
{
  "title": "Unsupervised Does Not Mean Uninterpretable: The Case for Word Sense Induction and Disambiguation",
  "authors": [
    "Chris Biemann",
    "Simone Paolo Ponzetto",
    "Stefano Faralli",
    "Alexander Panchenko",
    "E. Ruppert"
  ],
  "abstract": "The current trend in NLP is the use of highly opaque models, e.g. neural networks and word embeddings. While these models yield state-of-the-art results on a range of tasks, their drawback is poor interpretability. On the example of word sense induction and disambiguation (WSID), we show that it is possible to develop an interpretable model that matches the state-of-the-art models in accuracy. Namely, we present an unsupervised, knowledge-free WSID approach, which is interpretable at three levels: word sense inventory, sense feature representations, and disambiguation procedure. Experiments show that our model performs on par with state-of-the-art word sense embeddings and other unsupervised systems while offering the possibility to justify its decisions in human-readable form.",
  "links": [
    {
      "title": "PDF",
      "type": "pdf",
      "url": "https://pdfs.semanticscholar.org/bf37/d2c9185c0b90feb7a1bf872090f747d0fb6e.pdf"
    },
    {
      "title": "Semantic Scholar",
      "type": "semanticscholar",
      "url": "https://www.semanticscholar.org/paper/cfe62018b1f745078892d1f397364bca692499cd"
    }
  ],
  "supervision": [],
  "tasks": [],
  "methods": [],
  "thumbnail": "unsupervised-does-not-mean-uninterpretable-the-case-for-word-sense-induction-and-disambiguation-thumb.jpg",
  "card": "unsupervised-does-not-mean-uninterpretable-the-case-for-word-sense-induction-and-disambiguation-card.jpg",
  "s2_paper_id": "cfe62018b1f745078892d1f397364bca692499cd"
}
---


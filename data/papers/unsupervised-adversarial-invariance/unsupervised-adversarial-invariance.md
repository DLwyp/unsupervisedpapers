---
{
  "title": "Unsupervised Adversarial Invariance",
  "date": "2018-09-26",
  "authors": [
    "Ayush Jaiswal",
    "Y. Wu",
    "Wael AbdAlmageed",
    "P. Natarajan"
  ],
  "abstract": "Data representations that contain all the information about target variables but are invariant to nuisance factors benefit supervised learning algorithms by preventing them from learning associations between these factors and the targets, thus reducing overfitting. We present a novel unsupervised invariance induction framework for neural networks that learns a split representation of data through competitive training between the prediction task and a reconstruction task coupled with disentanglement, without needing any labeled information about nuisance factors or domain knowledge. We describe an adversarial instantiation of this framework and provide analysis of its working. Our unsupervised model outperforms state-of-the-art methods, which are supervised, at inducing invariance to inherent nuisance factors, effectively using synthetic data augmentation to learn invariance, and domain adaptation. Our method can be applied to any prediction task, eg., binary/multi-class classification or regression, without loss of generality.",
  "links": [
    {
      "resource": "PDF",
      "icon": "pdf",
      "url": "https://arxiv.org/pdf/1809.10083.pdf"
    },
    {
      "resource": "arXiv.org",
      "icon": "arxiv",
      "url": "https://arxiv.org/abs/1809.10083"
    },
    {
      "resource": "Semantic Scholar",
      "icon": "semanticscholar",
      "url": "https://www.semanticscholar.org/paper/3b032150d063079a7306c7c30335cd7db4e21329"
    }
  ],
  "supervision": [],
  "tasks": [],
  "methods": [],
  "thumbnail": "unsupervised-adversarial-invariance-thumb.jpg",
  "card": "unsupervised-adversarial-invariance-card.jpg",
  "s2_paper_id": "3b032150d063079a7306c7c30335cd7db4e21329"
}
---


---
{
  "title": "Unsupervised Paraphrasing without Translation",
  "date": "2019-05-29",
  "authors": [
    "Aurko Roy",
    "David Grangier"
  ],
  "abstract": "Paraphrasing exemplifies the ability to abstract semantic content from surface forms. Recent work on automatic paraphrasing is dominated by methods leveraging Machine Translation (MT) as an intermediate step. This contrasts with humans, who can paraphrase without being bilingual. This work proposes to learn paraphrasing models from an unlabeled monolingual corpus only. To that end, we propose a residual variant of vector-quantized variational auto-encoder. \nWe compare with MT-based approaches on paraphrase identification, generation, and training augmentation. Monolingual paraphrasing outperforms unsupervised translation in all settings. Comparisons with supervised translation are more mixed: monolingual paraphrasing is interesting for identification and augmentation; supervised translation is superior for generation.",
  "links": [
    {
      "title": "PDF",
      "type": "pdf",
      "url": "https://arxiv.org/pdf/1905.12752.pdf"
    },
    {
      "title": "arXiv.org",
      "type": "arxiv",
      "url": "https://arxiv.org/abs/1905.12752"
    },
    {
      "title": "Semantic Scholar",
      "type": "semanticscholar",
      "url": "https://www.semanticscholar.org/paper/4a70df03329fe23dc454273e87a95fa39396dd88"
    }
  ],
  "supervision": [],
  "tasks": [],
  "methods": [],
  "thumbnail": "unsupervised-paraphrasing-without-translation-thumb.jpg",
  "card": "unsupervised-paraphrasing-without-translation-card.jpg",
  "s2_paper_id": "4a70df03329fe23dc454273e87a95fa39396dd88"
}
---

